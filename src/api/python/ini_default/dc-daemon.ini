[Application]
instantiateSequence=AdminInterfaceServer,ClientInterfaceService,BatchTasksManager,BatchTasksManagerRealTime,BatchTasksManagerProcess,SitesManager
log=../ini/dc-daemon_log.ini
;DRCE nodes number in cluster used to adjust the limits fields for the Site and URL objects by division on nodes number to prevent redundancy of crawled data. For single host can omitted or set as 1.
DRCENodes=1

[AdminInterfaceServer]
server=Admin
serverHost=0.0.0.0
serverPort=5503
DRCENodes=1

[ClientInterfaceService]
serverHost=0.0.0.0
serverPort=5504
clientSitesManager=SitesManager
clientBatchTasksManagerRealTime=BatchTasksManagerRealTime

[BatchTasksManager]
server=BatchTasksManager
clientSitesManager=SitesManager
;Crawling command line
DRCECrawlerAppName=cd api/python/bin && ./crawler-task.py -c=../ini/crawler-task.ini
;DTM service connection
DTMDHost=127.0.0.1
DTMDPort=5501
DTMDTimeout=30000
;Periodic processes general timer, ms
PollingTimeout=5000
;Regular crawling period - time interval for crawl task create try; 0 - stops processing, sec
RegularCrawlingPeriod=20
;Regular crawling mode 0 - disabled, 1 - enabled
RegularCrawlingMode=1
;Insert URLs from Batch on all hosts to prevent redundant crawling
RegularCrawlingPropagateURLs=1
;Batching
BatchDefaultMaxExecutionTime=300
BatchDefaultMaxURLs=5
BatchDefaultMaxTasks=2
;Time interval for batch queue processing; 0 - stops processing, sec
BatchQueueProcessingPeriod=5
;BatchDefaultOrderByURLs=LENGTH(`ParentMd5`) ASC, DATE(`CDate`) DESC, HOUR(`CDate`) DESC, `URLMd5`
;BatchDefaultOrderByURLs=LENGTH(`ParentMd5`) ASC, Priority DESC, Depth ASC, `CDate` DESC
BatchDefaultOrderByURLs=LENGTH(`ParentMd5`) ASC, Priority DESC, Depth ASC, `UDate` DESC
;The FetcherType randomizer for sites selection, most typical usage to create batches only with dynamic or static fetcher type
;The value for a FetcherType condition calculated by formula: INT( (RAND()+1) > 1.33 ) + 1, that means 1/3 probability for dynamic fetcher and 2/3 - for static
;BatchDefaultFetchTypeOptions={"splitter":1.33,"dfetcher_BatchMaxExecutionTime":2000,"dfetcher_BatchQueueTaskTTL":2100,"dfetcher_BatchDefaultMaxURLs":2}
BatchDefaultFetchTypeOptions={"splitter":1.75,"dfetcher_BatchMaxExecutionTime":2400,"dfetcher_BatchQueueTaskTTL":2500,"dfetcher_BatchDefaultMaxURLs":4}
;Incremental crawling
IncrMinFreq=100
IncrMaxDepth=100
IncrMaxURLs=5
;Incremental crawling mode 0 - disabled, 1 - enabled
IncrMode=0
;Time interval for incremental crawling processing; 0 - stops processing, sec
IncrPeriod=0
;Max number of URLs to update state during return URLs processing request
ReturnURLsMaxNumber=500
;Period of processing of return URLs; 0 - stops processing, sec
ReturnURLsPeriod=600
;TTL of URLs in different processing states, min
ReturnURLsTTL=60
;Return URLs mode 0 - disabled, 1 - enabled
ReturnURLsMode=1
;Crawled URLs strategy for foreing hosts after the batch success: 0 - accumulate and update with Status=4 (CRAWLED), 1 - delete
CrawledURLStrategy=0
;DTM batch task's TTL in queue, sec
BatchQueueTaskTTL=900
;Check state method: 0 - DRCE EE request to hce-node host, 1 - DTM request to the TasksManager's table (no DRCE EE interaction, more fast but less actual in time)
BatchQueueTaskCheckStateMethod=1
;Batch task limits on DTM service to run: IO in %, CPU LA in %, RAM in bytes - are AVG on all data hosts in hce-node cluster; 30000 * 20 = 10 min max time to seat in schedule
BatchTask_IO_WAIT_MAX=30
BatchTask_CPU_LOAD_MAX=60
BatchTask_RAM_FREE_MIN=32000000
BatchTask_RDELAY=30000
BatchTask_RETRY=20
;DRCE task starter name
BatchTask_STARTER=hce-starter-dc-crawl.sh
;Set auto cleanup fields, -1 - to skip this field and not set for DTM task
BatchTask_autocleanup_TTL=1000
BatchTask_autocleanup_DeleteType=1
BatchTask_autocleanup_DeleteRetries=8
BatchTask_autocleanup_State=-1
;Check URL candidate on another active batch; to prevent near simultaneous crawling the same resource
BatchDefaultCheckURLsInActiveBatches=1
;Purging batch mode 0 - disabled, 1 - enabled
PurgeMode=1
;Max number of purge tasks in tasks queue, in competition with the BatchDefaultMaxTasks limit
PurgeBatchDefaultMaxTasks=2
;Period of time between try to create the purge task; 0 - stops processing, min
PurgePeriod=2
;Max time for DRCE task of purge batch, sec
PurgeBatchDefaultMaxExecutionTime=3600
;Max items number to delete in one task
PurgeBatchDefaultMaxURLs=100
;TTL of the purge batch task in tasks queue, if exceeded - DRCE task will be deleted and purging task will be aborted, sec
PurgeBatchQueueTaskTTL=4000
PurgeBatchTask_STARTER=hce-starter-bash.sh
DRCEDBAppName=cd api/python/bin && ./db-task.py --c=../ini/db-task.ini
;Batch task DTM service names and types
BatchTaskDTMNameCrawl=crawl
BatchTaskDTMNamePurge=purge
BatchTaskDTMNameAging=aging
BatchTaskDTMTypeCrawl=1
BatchTaskDTMTypePurge=2
BatchTaskDTMTypeAging=3
;Resources aging mode 0 - disabled, 1 - enabled
AgingMode=1
;Resources aging processing period; 0 - stops processing, min
AgingPeriod=2
;Max time for DRCE task of aging batch, sec
AgingBatchDefaultMaxExecutionTime=3600
;Total max items number of URLs to delete in one task
AgingBatchDefaultMaxURLsTotal=10000
;Max items number of URLs to delete per site
AgingBatchDefaultMaxURLsSite=100
;Max sites number to use for aging batch, 0 - means all
AgingBatchDefaultMaxSites=0
;TTL of the aging batch task in tasks queue, if exceeded - DRCE task will be deleted and aging task will be aborted, sec
AgingBatchQueueTaskTTL=4000
AgingBatchTask_STARTER=hce-starter-bash.sh
AgingBatchDefaultMaxTasks=2
;URLs selection criterion
;AgingBatchURLsCriterion=NOW() > DATE_ADD(CDate, INTERVAL IFNULL((SELECT `Value` FROM `dc_sites`.`sites_properties` WHERE `Site_Id`='%SITE_ID%' AND `Name`='AGING_URL_TTL'), 15) MINUTE) AND ParentMd5<>''
;AgingBatchURLsCriterion=NOW() > DATE_ADD(CDate, INTERVAL ((SELECT `RecrawlPeriod` FROM `dc_sites`.`sites` WHERE `Id`='%SITE_ID%')*1) MINUTE) AND ParentMd5<>''
;AgingBatchURLsCriterion=NOW() > DATE_ADD(UDate, INTERVAL ((SELECT `RecrawlPeriod` FROM `dc_sites`.`sites` WHERE `Id`='%SITE_ID%')*1) MINUTE) AND ParentMd5<>''
AgingBatchURLsCriterion=(NOW() > DATE_ADD(UDate, INTERVAL ((SELECT `RecrawlPeriod` FROM `dc_sites`.`sites` WHERE `Id`='%SITE_ID%')*2) MINUTE) OR ( NOW() > DATE_ADD(CDate, INTERVAL ((SELECT `RecrawlPeriod` FROM `dc_sites`.`sites` WHERE `Id`='%SITE_ID%')*2) MINUTE) AND UDate IS NULL) ) AND ParentMd5<>''
AgingBatchSitesCriterion=`sites`.`Id`<>'0' AND `sites`.`State` IN (1,3) AND IFNULL((SELECT `Value` FROM `sites_properties` WHERE `Name`='MODES_FLAG') & 16, 1)<>0
;The max. iterations for the batch to process collected URLs in one batch task
BatchMaxIterations=1
BatchMaxExecutionTime=360
RemoveUnprocessedBatchItems=0

[BatchTasksManagerProcess]
server=BatchTasksManagerProcess
clientSitesManager=SitesManager
;Process command line
DRCEProcessorAppName=cd api/python/bin && ./processor-task.py -c=../ini/processor-task.ini
;DTM service connection
DTMDHost=127.0.0.1
DTMDPort=5501
DTMDTimeout=30000
;Periodic processes general timer, ms
PollingTimeout=5000
;Time interval for crawl task create try; 0 - stops processing, sec
ProcessingPeriod=20
;Batching
BatchDefaultMaxExecutionTime=300
BatchDefaultMaxURLs=5
BatchDefaultMaxTasks=2
BatchQueueProcessingPeriod=5
;BatchDefaultOrderByURLs=LENGTH(`ParentMd5`) ASC, Priority DESC, Depth ASC, `CDate` DESC
BatchDefaultOrderByURLs=LENGTH(`ParentMd5`) ASC, Priority DESC, Depth ASC, `UDate` DESC
BatchDefaultWhereURLs=`Type`<>6 AND `Status`=4 AND `State`=0 AND `Crawled`>0 AND `Size`>0 AND ((`ErrorMask` & 4198399) = 0) AND `ContentType` IN ('text/html', 'text/json') AND `HTTPCode`='200' AND `ParentMd5`<>''
BatchDefaultWhereSites=`sites`.`Id`<>'0' AND `sites`.`State`=1 AND IFNULL((SELECT `Value` FROM `dc_sites`.`sites_properties` WHERE `Name`='MODES_FLAG') & 2, 1)<>0
;DTM batch task's TTL in queue, sec
BatchQueueTaskTTL=900
;Check state method: 0 - DRCE EE request to hce-node host, 1 - DTM request to the TasksManager's table (no DRCE EE interaction, more fast but less actual in time)
BatchQueueTaskCheckStateMethod=1
;Batch task limits on DTM service to run: IO in %, CPU LA in %, RAM in bytes - are AVG on all data hosts in hce-node cluster; 30000 * 20 = 10 min max time to seat in schedule
BatchTask_IO_WAIT_MAX=30
BatchTask_CPU_LOAD_MAX=60
BatchTask_RAM_FREE_MIN=32000000
BatchTask_RDELAY=30000
BatchTask_RETRY=20
;DRCE task starter name
BatchTask_STARTER=hce-starter-dc-process.sh
;Set auto cleanup fields, -1 - to skip this field and not set for DTM task
BatchTask_autocleanup_TTL=1000
BatchTask_autocleanup_DeleteType=1
BatchTask_autocleanup_DeleteRetries=8
BatchTask_autocleanup_State=-1
DRCEDBAppName=cd api/python/bin && ./db-task.py --c=../ini/db-task.ini
;Processing mode 0 - disabled, 1 - enabled
ProcessingMode=1
;Batch task DTM service name and type
BatchTaskDTMNameProcess=process
BatchTaskDTMTypeProcess=4
BatchMaxExecutionTime=360
RemoveUnprocessedBatchItems=0

[BatchTasksManagerRealTime]
server=BatchTasksManagerRealTime
;HCE node cluster m-type router and DRCE request parameters
DRCEHost=127.0.0.1
DRCEPort=5756
DRCETimeout=1200000
DRCEStarterName=hce-starter-dc-rt.sh
;Crawling command line
DRCECrawlerAppName=cd api/python/bin && (./rtc-preprocessor.py -c=../ini/rtc-preprocessor.ini | ./crawler-task.py -c=../ini/crawler-task.ini)
;Batching
BatchMaxURLs=10
BatchMaxExecutionTime=360
MaxThreads=6
PollingTimeout=5000
;The hce-node routing type for the case of one item in the batch to avoid multiplication of the task for all nodes
DRCERequestRouting=1
;The max. iterations for the batch to process collected URLs in one batch task
BatchMaxIterations=10

[SitesManager]
;Inproc server name
server=SitesManager
;HCE node cluster m-type (5656) router and DRCE request parameters; if route used n-type cluster need to be set can port 5556
DRCEHost=127.0.0.1
DRCEPort=5656
DRCETimeout=90000
DRCEDBAppName=cd api/python/bin && ./db-task.py --c=../ini/db-task.ini
;DRCERoute={"role": 0,"nodes": []}
DRCERoute=
;Recrawl sites mode 0 - disabled, 1 - enabled
RecrawlSiteMode=1
;Auto re-crawl max sites per iteration
RecrawlSiteMax=1
;Auto re-crawl iteration period; 0 - stops processing, sec
RecrawlSiteIterationPeriod=60
;RecrawlDate calculation expression
;RecrawlSiteRecrawlDateExpression=DATE_ADD(DATE_FORMAT(NOW(),'%Y-%m-%d 00:00:00'), INTERVAL ( ( ( ( HOUR(NOW())*60 + MINUTE(NOW()) + SECOND(NOW())/60) DIV RecrawlPeriod )*RecrawlPeriod ) + RecrawlPeriod ) MINUTE)
RecrawlSiteRecrawlDateExpression=DATE_ADD(DATE_FORMAT(NOW(),'%Y-%m-%d 00:00:00'), INTERVAL ( CEIL( ( ( HOUR(NOW())*60 + MINUTE(NOW()) + SECOND(NOW())/60) / `RecrawlPeriod` )*`RecrawlPeriod` ) + `RecrawlPeriod` ) MINUTE)
;Recrawl sites select criterion
;RecrawlSiteSelectCriterion=`State`=1 AND `RecrawlDate` IS NOT NULL AND NOW()>`RecrawlDate` AND IFNULL((SELECT `Value` FROM `sites_properties` WHERE `Name`='MODES_FLAG') & 8, 1)<>0
RecrawlSiteSelectCriterion=`State`=1 AND `RecrawlDate` IS NOT NULL AND NOW()>`RecrawlDate` AND (Id IN (SELECT Site_Id AS Id FROM `sites_properties` WHERE `Name`='MODES_FLAG' AND (`Value` & 8)>0) OR Id IN (SELECT Site_Id AS Id FROM `sites_properties` WHERE `Name`<>'MODES_FLAG'))

;Recrawl sites select order
RecrawlSiteSelectOrder=`RecrawlDate` ASC
;Recrawl threads max number
RecrawlSiteMaxThreads=2
;Recrawl site lock sites.state db field value, typically is 4 (recrawl) or 3 (suspended)
RecrawlSiteLockState=4
;Recrawl optimize DB tables before project activate by default if site has no properties value with name "RECRAWL_OPTIMIZE"
RecrawlSiteOptimize=1
;Recrawl operations DRCE request timeout, sec
RecrawlSiteDRCETimeout=3600
;Mode of auto-recrawl period for sites: 0 - fixed from the `dc_sites`.`sites`.`RecrawlPeriod` value; 1 - auto tunned
RecrawlSitePeriodMode=0
;Max value of re-crawl period that can be automatically set for site
RecrawlSitePeriodMax=1440
;Min value of re-crawl period that can be automatically set for site
RecrawlSitePeriodMin=15
;Step of change of the RecrawlPeriod value during auto tuning process depends on the RecrawlSitePeriodCriterion>0 result (increment or decrement)
RecrawlSitePeriodStep=15
RecrawlDelayBefore=60
;Recrawl delay after re-crawl steps finish - to get possibility to end some I/O operations, sec
RecrawlDelayAfter=60
;Periodic processes general timer, ms
PollingTimeout=10000
;Default re-crawl criterion for URL update to NEW state if dc_sites.sites_properties["RECRAWL_WHERE"] is not set or empty
;Conditions to renew all already crawled URLs
;DefaultRecrawUpdatelCriterion=State=0 AND Status>3 AND Crawled>0
;Conditions to renew only site's root URLs
DefaultRecrawUpdatelCriterion=ParentMd5=''
;Default operation for URLs from prev. iteration before re-crawling update - 0 - do nothing, 1 - delete with condition criterion
DefaultRecrawDeleteOld=0
;Default condition criterion for delete operation for URLs from prev. iteration before re-crawling update
;DefaultRecrawDeleteOldCriterion=(`Status`=1 OR (`Status`=4 AND Crawled=0 AND Processed=0) OR `PDate`<CURDATE() OR `PDate` IS NULL OR CDate<CURDATE()) AND `ParentMd5`<>''
DefaultRecrawDeleteOldCriterion=((`Status`=4 AND `Crawled`=0 AND `Processed`=0) OR (`Status`=4 AND `Crawled`>0 AND `Processed`=0 AND `ErrorMask`>0) OR (`Status`=7 AND `TagsCount`=0)) AND `ParentMd5`<>''
;Recrawl delete resources - purge method, 1 - delete immediately without delay and purging; 0 - delete with move to temporary place with purging algorithm
PurgeMethod=0
;Number of the DRCE data nodes in the m-cluster
DRCENodes=1
;Optional common commands threading mode, 0 - simple not threading (default), 1 - multi-thread
;CommonCommandsThreadingMode=1
;Optional DRCE m-type hce-node cluster router's connections pool in json format: {"host:port:timeout":[eventCode1,eventCode2,...], ...}
;Single basic DRCE m-type cluster connection used by default
;Example for second additional m-type cluster long-time playing events like SITE_DELETE, SITE_CLEANUP and URL_CONTENT request:
;DRCEConnectionsPool={"127.0.0.1:5856:600000":[4,5,12]}
