[Application]
log=../ini/scraper_multi_items_task_log.ini
template=../ini/scraper_template.txt
default_template={}
property_file_name=../ini/scraper.json

[Profiler]
# If set 1 - the profiler log will be created
profile=0
# 'sortby' has allowed values: stdname, calls, time, cumulative
sortby=cumulative
# Set the limit of output lines in log for one application start number. Allowed values from 0.0 to 1.0
limit=0.1
# If set 1 - the traceback log will be created. Note that this process is CPU expensive
traceback=0

[DateTimeType]
# If set value more 0 - filling didn't select year as current
useCurrentYear=1

[sqlite]
timeout = 30
articles_tbl: articles
PRAGMA_synchronous=OFF
PRAGMA_journal_mode=MEMORY
PRAGMA_temp_store=MEMORY

[mysql]
db_host=127.0.0.1
db_port=3306
db_user=hce
db_pwd=hce12345
db_dc_scrapers=dc_processor
db_dc_contents=dc_contents

[ScraperMultiItemsTask]
tagsTypes={"author":{"min_words":1,"max_words": 8,"min_bytes":3,"max_bytes":32,"mismatch":"empty"}}
db-task_ini=../ini/db-task.ini

db_dc_contents=dc_contents

[NewspaperExtractor]
db_dc_scrapers=scraper_main
#db_dc_scrapers=db_newspaper

[GooseExtractor]
db_dc_scrapers=scraper_main
#db_dc_scrapers=db_goose

[ScrapyExtractor]
db_dc_scrapers=scraper_main
#db_dc_scrapers=db_scrapy

[MLExtractor]
db_dc_scrapers=scraper_main
#db_dc_scrapers=db_mle

[AlchemyExtractor]
db_dc_scrapers=scraper_main

[BoilerpipeExtractor]
db_dc_scrapers=scraper_main

[article_tags]
title:
link:
description:
pubdate:
author:
guid:
dc_date:
content_encoded:
keywords:
media:
enclosure:
media_content:
media_thumbnail:
google_search:
google_search_total:
html_lang:

[tags_datetime_news_names]
pubdate:
dc_date:

[tags_datetime_template_types]
datetime:
